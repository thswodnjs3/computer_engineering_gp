{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_png = sorted(glob('./open/train/*.png'))\n",
    "test_png = sorted(glob('./open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 2154)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_png), len(test_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"./open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 163/4277 [00:03<01:33, 43.92it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7352/2141366604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_png\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_png\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7352/2141366604.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_png\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_png\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7352/2339306042.py\u001b[0m in \u001b[0;36mimg_load\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimg_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m384\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m384\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./save/train_imgs_384', np.array(train_imgs))\n",
    "np.save('./save/test_imgs_384', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load('./save/train_imgs_384.npy')\n",
    "test_imgs = np.load('./save/test_imgs_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.4330380901867049 0.4034575319032911 0.39415050509784405\n",
      "train 표준편차 0.1815717110252788 0.17403455556798705 0.16323395055036488\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"train 평균\",meanR, meanG, meanB)\n",
    "print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.41825619520929724 0.3931011906330291 0.386631764639131\n",
      "test 표준편차 0.19505524270747931 0.19005280951759498 0.18053225852732663\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "print(\"test 평균\",meanR, meanG, meanB)\n",
    "print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 163/4277 [00:20<01:33, 43.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 114s/7898s\n",
      "TRAIN    loss : 1.07745    f1 : 0.19511\n",
      "Val    loss : 0.58840    f1 : 0.31208\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 102s/6932s\n",
      "TRAIN    loss : 0.54709    f1 : 0.38922\n",
      "Val    loss : 0.40714    f1 : 0.47081\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 103s/6920s\n",
      "TRAIN    loss : 0.36941    f1 : 0.52961\n",
      "Val    loss : 0.32156    f1 : 0.57020\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 105s/6935s\n",
      "TRAIN    loss : 0.28453    f1 : 0.63502\n",
      "Val    loss : 0.29064    f1 : 0.63231\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 106s/6867s\n",
      "TRAIN    loss : 0.21027    f1 : 0.72595\n",
      "Val    loss : 0.40196    f1 : 0.63297\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 106s/6770s\n",
      "TRAIN    loss : 0.18390    f1 : 0.76712\n",
      "Val    loss : 0.24777    f1 : 0.74168\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 106s/6682s\n",
      "TRAIN    loss : 0.13647    f1 : 0.85171\n",
      "Val    loss : 0.23876    f1 : 0.74475\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 106s/6551s\n",
      "TRAIN    loss : 0.11444    f1 : 0.85921\n",
      "Val    loss : 0.17018    f1 : 0.80191\n",
      "epoch : 9/70    time : 105s/6421s\n",
      "TRAIN    loss : 0.12529    f1 : 0.87134\n",
      "Val    loss : 0.21325    f1 : 0.75640\n",
      "epoch : 10/70    time : 104s/6214s\n",
      "TRAIN    loss : 0.10573    f1 : 0.87295\n",
      "Val    loss : 0.35050    f1 : 0.78842\n",
      "epoch : 11/70    time : 103s/6104s\n",
      "TRAIN    loss : 0.09229    f1 : 0.90513\n",
      "Val    loss : 0.21369    f1 : 0.74196\n",
      "epoch : 12/70    time : 105s/6097s\n",
      "TRAIN    loss : 0.08127    f1 : 0.91502\n",
      "Val    loss : 0.27580    f1 : 0.72684\n",
      "epoch : 13/70    time : 106s/6045s\n",
      "TRAIN    loss : 0.07353    f1 : 0.90460\n",
      "Val    loss : 0.20933    f1 : 0.79211\n",
      "epoch : 14/70    time : 109s/6083s\n",
      "TRAIN    loss : 0.07416    f1 : 0.91456\n",
      "Val    loss : 0.22618    f1 : 0.80155\n",
      "epoch : 15/70    time : 108s/5913s\n",
      "TRAIN    loss : 0.05736    f1 : 0.95058\n",
      "Val    loss : 0.24003    f1 : 0.78220\n",
      "epoch : 16/70    time : 108s/5850s\n",
      "TRAIN    loss : 0.06519    f1 : 0.93398\n",
      "Val    loss : 0.23730    f1 : 0.75432\n",
      "epoch : 17/70    time : 108s/5739s\n",
      "TRAIN    loss : 0.03906    f1 : 0.96105\n",
      "Val    loss : 0.19755    f1 : 0.78922\n",
      "epoch : 18/70    time : 108s/5629s\n",
      "TRAIN    loss : 0.05038    f1 : 0.94964\n",
      "Val    loss : 0.24028    f1 : 0.75345\n",
      "epoch : 19/70    time : 108s/5509s\n",
      "TRAIN    loss : 0.03531    f1 : 0.96497\n",
      "Val    loss : 0.40685    f1 : 0.76376\n",
      "epoch : 20/70    time : 106s/5317s\n",
      "TRAIN    loss : 0.05712    f1 : 0.95035\n",
      "Val    loss : 0.29810    f1 : 0.76208\n",
      "epoch : 21/70    time : 105s/5157s\n",
      "TRAIN    loss : 0.04679    f1 : 0.95317\n",
      "Val    loss : 0.29025    f1 : 0.74845\n",
      "epoch : 22/70    time : 105s/5055s\n",
      "TRAIN    loss : 0.05722    f1 : 0.94896\n",
      "Val    loss : 0.26759    f1 : 0.78337\n",
      "epoch : 23/70    time : 110s/5172s\n",
      "TRAIN    loss : 0.03314    f1 : 0.96835\n",
      "Val    loss : 0.26532    f1 : 0.77835\n",
      "epoch : 24/70    time : 105s/4829s\n",
      "TRAIN    loss : 0.03584    f1 : 0.95387\n",
      "Val    loss : 0.28945    f1 : 0.78964\n",
      "epoch : 25/70    time : 105s/4732s\n",
      "TRAIN    loss : 0.03604    f1 : 0.95780\n",
      "Val    loss : 0.72610    f1 : 0.80030\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/70    time : 105s/4638s\n",
      "TRAIN    loss : 0.04760    f1 : 0.96046\n",
      "Val    loss : 0.37460    f1 : 0.80749\n",
      "epoch : 27/70    time : 105s/4511s\n",
      "TRAIN    loss : 0.05174    f1 : 0.96123\n",
      "Val    loss : 0.20106    f1 : 0.73885\n",
      "epoch : 28/70    time : 106s/4437s\n",
      "TRAIN    loss : 0.03670    f1 : 0.95512\n",
      "Val    loss : 0.22102    f1 : 0.78152\n",
      "epoch : 29/70    time : 107s/4367s\n",
      "TRAIN    loss : 0.03162    f1 : 0.96549\n",
      "Val    loss : 0.21993    f1 : 0.79980\n",
      "-----------------SAVE:30 epoch----------------\n",
      "epoch : 30/70    time : 104s/4153s\n",
      "TRAIN    loss : 0.02633    f1 : 0.96880\n",
      "Val    loss : 0.17808    f1 : 0.81160\n",
      "-----------------SAVE:31 epoch----------------\n",
      "epoch : 31/70    time : 106s/4141s\n",
      "TRAIN    loss : 0.04647    f1 : 0.94180\n",
      "Val    loss : 0.18279    f1 : 0.82762\n",
      "epoch : 32/70    time : 106s/4032s\n",
      "TRAIN    loss : 0.02783    f1 : 0.96964\n",
      "Val    loss : 0.18212    f1 : 0.82030\n",
      "epoch : 33/70    time : 106s/3920s\n",
      "TRAIN    loss : 0.03416    f1 : 0.97094\n",
      "Val    loss : 0.20883    f1 : 0.81387\n",
      "epoch : 34/70    time : 103s/3691s\n",
      "TRAIN    loss : 0.02417    f1 : 0.97722\n",
      "Val    loss : 0.26009    f1 : 0.78211\n",
      "epoch : 35/70    time : 103s/3609s\n",
      "TRAIN    loss : 0.02899    f1 : 0.96913\n",
      "Val    loss : 0.19189    f1 : 0.79900\n",
      "epoch : 36/70    time : 103s/3517s\n",
      "TRAIN    loss : 0.03107    f1 : 0.96935\n",
      "Val    loss : 0.30765    f1 : 0.79095\n",
      "epoch : 37/70    time : 105s/3452s\n",
      "TRAIN    loss : 0.04564    f1 : 0.96355\n",
      "Val    loss : 0.17645    f1 : 0.82535\n",
      "epoch : 38/70    time : 105s/3370s\n",
      "TRAIN    loss : 0.02803    f1 : 0.97872\n",
      "Val    loss : 0.19290    f1 : 0.81372\n",
      "epoch : 39/70    time : 102s/3171s\n",
      "TRAIN    loss : 0.03584    f1 : 0.97687\n",
      "Val    loss : 0.21803    f1 : 0.80605\n",
      "epoch : 40/70    time : 102s/3051s\n",
      "TRAIN    loss : 0.03261    f1 : 0.97682\n",
      "Val    loss : 0.22575    f1 : 0.81495\n",
      "epoch : 41/70    time : 102s/2953s\n",
      "TRAIN    loss : 0.02241    f1 : 0.98292\n",
      "Val    loss : 0.22601    f1 : 0.80782\n",
      "-----------------SAVE:42 epoch----------------\n",
      "epoch : 42/70    time : 102s/2865s\n",
      "TRAIN    loss : 0.02878    f1 : 0.98021\n",
      "Val    loss : 0.24622    f1 : 0.83491\n",
      "epoch : 43/70    time : 106s/2859s\n",
      "TRAIN    loss : 0.03249    f1 : 0.96415\n",
      "Val    loss : 0.26119    f1 : 0.76268\n",
      "epoch : 44/70    time : 104s/2716s\n",
      "TRAIN    loss : 0.03577    f1 : 0.96664\n",
      "Val    loss : 0.26474    f1 : 0.77889\n",
      "-----------------SAVE:45 epoch----------------\n",
      "epoch : 45/70    time : 105s/2614s\n",
      "TRAIN    loss : 0.02969    f1 : 0.96527\n",
      "Val    loss : 0.17637    f1 : 0.83789\n",
      "-----------------SAVE:46 epoch----------------\n",
      "epoch : 46/70    time : 104s/2505s\n",
      "TRAIN    loss : 0.01723    f1 : 0.97876\n",
      "Val    loss : 0.20082    f1 : 0.84179\n",
      "epoch : 47/70    time : 104s/2389s\n",
      "TRAIN    loss : 0.01281    f1 : 0.98396\n",
      "Val    loss : 0.18084    f1 : 0.81415\n",
      "epoch : 48/70    time : 104s/2296s\n",
      "TRAIN    loss : 0.01878    f1 : 0.97803\n",
      "Val    loss : 0.22573    f1 : 0.78787\n",
      "epoch : 49/70    time : 105s/2207s\n",
      "TRAIN    loss : 0.04531    f1 : 0.95009\n",
      "Val    loss : 0.27647    f1 : 0.78956\n",
      "epoch : 50/70    time : 104s/2083s\n",
      "TRAIN    loss : 0.02496    f1 : 0.98060\n",
      "Val    loss : 0.22963    f1 : 0.80779\n",
      "epoch : 51/70    time : 104s/1984s\n",
      "TRAIN    loss : 0.01968    f1 : 0.97752\n",
      "Val    loss : 0.20657    f1 : 0.83058\n",
      "epoch : 52/70    time : 105s/1884s\n",
      "TRAIN    loss : 0.01946    f1 : 0.98821\n",
      "Val    loss : 0.44400    f1 : 0.76573\n",
      "epoch : 53/70    time : 104s/1767s\n",
      "TRAIN    loss : 0.02061    f1 : 0.99062\n",
      "Val    loss : 0.32519    f1 : 0.75949\n",
      "epoch : 54/70    time : 103s/1648s\n",
      "TRAIN    loss : 0.04352    f1 : 0.95936\n",
      "Val    loss : 0.31802    f1 : 0.76052\n",
      "epoch : 55/70    time : 105s/1571s\n",
      "TRAIN    loss : 0.03612    f1 : 0.96222\n",
      "Val    loss : 0.38714    f1 : 0.79386\n",
      "epoch : 56/70    time : 105s/1476s\n",
      "TRAIN    loss : 0.02114    f1 : 0.97557\n",
      "Val    loss : 0.24652    f1 : 0.82719\n",
      "epoch : 57/70    time : 103s/1341s\n",
      "TRAIN    loss : 0.01927    f1 : 0.98831\n",
      "Val    loss : 0.23909    f1 : 0.83588\n",
      "epoch : 58/70    time : 103s/1237s\n",
      "TRAIN    loss : 0.02184    f1 : 0.98253\n",
      "Val    loss : 0.27218    f1 : 0.79563\n",
      "epoch : 59/70    time : 103s/1137s\n",
      "TRAIN    loss : 0.01082    f1 : 0.98826\n",
      "Val    loss : 0.28623    f1 : 0.79118\n",
      "epoch : 60/70    time : 105s/1051s\n",
      "TRAIN    loss : 0.00380    f1 : 0.99489\n",
      "Val    loss : 0.27134    f1 : 0.79939\n",
      "epoch : 61/70    time : 103s/929s\n",
      "TRAIN    loss : 0.01641    f1 : 0.98693\n",
      "Val    loss : 0.34853    f1 : 0.75555\n",
      "epoch : 62/70    time : 102s/820s\n",
      "TRAIN    loss : 0.04100    f1 : 0.95962\n",
      "Val    loss : 0.32077    f1 : 0.79760\n",
      "epoch : 63/70    time : 103s/721s\n",
      "TRAIN    loss : 0.02317    f1 : 0.98067\n",
      "Val    loss : 0.30432    f1 : 0.73762\n",
      "epoch : 64/70    time : 105s/628s\n",
      "TRAIN    loss : 0.03902    f1 : 0.96292\n",
      "Val    loss : 0.23819    f1 : 0.78748\n",
      "epoch : 65/70    time : 103s/513s\n",
      "TRAIN    loss : 0.01274    f1 : 0.99102\n",
      "Val    loss : 0.27005    f1 : 0.80775\n",
      "epoch : 66/70    time : 103s/413s\n",
      "TRAIN    loss : 0.02033    f1 : 0.98473\n",
      "Val    loss : 0.24830    f1 : 0.77038\n",
      "----------fold_1 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 103s/7103s\n",
      "TRAIN    loss : 1.09091    f1 : 0.21484\n",
      "Val    loss : 0.61385    f1 : 0.31228\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 104s/7096s\n",
      "TRAIN    loss : 0.53964    f1 : 0.37929\n",
      "Val    loss : 0.35926    f1 : 0.49399\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 102s/6867s\n",
      "TRAIN    loss : 0.38124    f1 : 0.52210\n",
      "Val    loss : 0.32661    f1 : 0.54550\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 102s/6709s\n",
      "TRAIN    loss : 0.27676    f1 : 0.64830\n",
      "Val    loss : 0.32915    f1 : 0.59997\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 102s/6629s\n",
      "TRAIN    loss : 0.21672    f1 : 0.70048\n",
      "Val    loss : 0.26463    f1 : 0.68068\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 102s/6544s\n",
      "TRAIN    loss : 0.19795    f1 : 0.74445\n",
      "Val    loss : 0.26254    f1 : 0.72493\n",
      "epoch : 7/70    time : 102s/6400s\n",
      "TRAIN    loss : 0.14876    f1 : 0.80479\n",
      "Val    loss : 0.18143    f1 : 0.72376\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 103s/6415s\n",
      "TRAIN    loss : 0.12346    f1 : 0.84296\n",
      "Val    loss : 0.22724    f1 : 0.75323\n",
      "epoch : 9/70    time : 105s/6404s\n",
      "TRAIN    loss : 0.11051    f1 : 0.88025\n",
      "Val    loss : 0.21281    f1 : 0.75271\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 10/70    time : 110s/6592s\n",
      "TRAIN    loss : 0.10203    f1 : 0.86894\n",
      "Val    loss : 0.20160    f1 : 0.77648\n",
      "epoch : 11/70    time : 112s/6604s\n",
      "TRAIN    loss : 0.07421    f1 : 0.90661\n",
      "Val    loss : 0.16351    f1 : 0.76445\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 104s/6049s\n",
      "TRAIN    loss : 0.07799    f1 : 0.91510\n",
      "Val    loss : 0.17827    f1 : 0.78037\n",
      "-----------------SAVE:13 epoch----------------\n",
      "epoch : 13/70    time : 103s/5880s\n",
      "TRAIN    loss : 0.07686    f1 : 0.90451\n",
      "Val    loss : 0.15581    f1 : 0.80253\n",
      "epoch : 14/70    time : 103s/5759s\n",
      "TRAIN    loss : 0.06515    f1 : 0.92983\n",
      "Val    loss : 0.17482    f1 : 0.79120\n",
      "epoch : 15/70    time : 110s/6038s\n",
      "TRAIN    loss : 0.08553    f1 : 0.92186\n",
      "Val    loss : 0.19050    f1 : 0.79010\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/70    time : 111s/5992s\n",
      "TRAIN    loss : 0.05006    f1 : 0.93461\n",
      "Val    loss : 0.21813    f1 : 0.81480\n",
      "epoch : 17/70    time : 102s/5396s\n",
      "TRAIN    loss : 0.06578    f1 : 0.93789\n",
      "Val    loss : 0.20199    f1 : 0.81103\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/70    time : 102s/5297s\n",
      "TRAIN    loss : 0.05655    f1 : 0.94836\n",
      "Val    loss : 0.19693    f1 : 0.82047\n",
      "epoch : 19/70    time : 101s/5165s\n",
      "TRAIN    loss : 0.06297    f1 : 0.93824\n",
      "Val    loss : 0.24887    f1 : 0.79129\n",
      "epoch : 20/70    time : 101s/5068s\n",
      "TRAIN    loss : 0.06334    f1 : 0.92912\n",
      "Val    loss : 0.20309    f1 : 0.77317\n",
      "-----------------SAVE:21 epoch----------------\n",
      "epoch : 21/70    time : 101s/4971s\n",
      "TRAIN    loss : 0.03201    f1 : 0.96124\n",
      "Val    loss : 0.16254    f1 : 0.84489\n",
      "epoch : 22/70    time : 101s/4861s\n",
      "TRAIN    loss : 0.04541    f1 : 0.96568\n",
      "Val    loss : 0.23436    f1 : 0.80846\n",
      "epoch : 23/70    time : 101s/4752s\n",
      "TRAIN    loss : 0.06318    f1 : 0.95610\n",
      "Val    loss : 0.18920    f1 : 0.80954\n",
      "epoch : 24/70    time : 101s/4658s\n",
      "TRAIN    loss : 0.03107    f1 : 0.97592\n",
      "Val    loss : 0.22872    f1 : 0.81005\n",
      "epoch : 25/70    time : 101s/4555s\n",
      "TRAIN    loss : 0.06263    f1 : 0.94759\n",
      "Val    loss : 0.21323    f1 : 0.79043\n",
      "epoch : 26/70    time : 101s/4445s\n",
      "TRAIN    loss : 0.04658    f1 : 0.95036\n",
      "Val    loss : 0.18860    f1 : 0.80763\n",
      "epoch : 27/70    time : 101s/4350s\n",
      "TRAIN    loss : 0.03233    f1 : 0.96541\n",
      "Val    loss : 0.24252    f1 : 0.79800\n",
      "epoch : 28/70    time : 101s/4248s\n",
      "TRAIN    loss : 0.03610    f1 : 0.96133\n",
      "Val    loss : 0.25057    f1 : 0.76882\n",
      "epoch : 29/70    time : 101s/4147s\n",
      "TRAIN    loss : 0.02381    f1 : 0.97942\n",
      "Val    loss : 0.24693    f1 : 0.80491\n",
      "epoch : 30/70    time : 101s/4044s\n",
      "TRAIN    loss : 0.01981    f1 : 0.97829\n",
      "Val    loss : 0.22474    f1 : 0.82755\n",
      "epoch : 31/70    time : 101s/3941s\n",
      "TRAIN    loss : 0.04385    f1 : 0.95803\n",
      "Val    loss : 0.21313    f1 : 0.80476\n",
      "epoch : 32/70    time : 102s/3863s\n",
      "TRAIN    loss : 0.02638    f1 : 0.98490\n",
      "Val    loss : 0.19251    f1 : 0.81735\n",
      "epoch : 33/70    time : 101s/3735s\n",
      "TRAIN    loss : 0.03878    f1 : 0.97074\n",
      "Val    loss : 0.21763    f1 : 0.82235\n",
      "epoch : 34/70    time : 101s/3641s\n",
      "TRAIN    loss : 0.03063    f1 : 0.96620\n",
      "Val    loss : 0.24417    f1 : 0.76706\n",
      "epoch : 35/70    time : 101s/3538s\n",
      "TRAIN    loss : 0.04333    f1 : 0.96040\n",
      "Val    loss : 0.19264    f1 : 0.79669\n",
      "epoch : 36/70    time : 101s/3450s\n",
      "TRAIN    loss : 0.02939    f1 : 0.96606\n",
      "Val    loss : 0.28039    f1 : 0.75104\n",
      "epoch : 37/70    time : 105s/3468s\n",
      "TRAIN    loss : 0.02489    f1 : 0.97014\n",
      "Val    loss : 0.30602    f1 : 0.78215\n",
      "epoch : 38/70    time : 101s/3226s\n",
      "TRAIN    loss : 0.03270    f1 : 0.96070\n",
      "Val    loss : 0.22914    f1 : 0.81327\n",
      "epoch : 39/70    time : 101s/3121s\n",
      "TRAIN    loss : 0.02928    f1 : 0.96891\n",
      "Val    loss : 0.21198    f1 : 0.80694\n",
      "epoch : 40/70    time : 101s/3022s\n",
      "TRAIN    loss : 0.01925    f1 : 0.98153\n",
      "Val    loss : 0.17223    f1 : 0.81618\n",
      "-----------------SAVE:41 epoch----------------\n",
      "epoch : 41/70    time : 101s/2928s\n",
      "TRAIN    loss : 0.02794    f1 : 0.97946\n",
      "Val    loss : 0.15632    f1 : 0.85312\n",
      "epoch : 42/70    time : 101s/2820s\n",
      "TRAIN    loss : 0.03428    f1 : 0.96778\n",
      "Val    loss : 0.16390    f1 : 0.84849\n",
      "epoch : 43/70    time : 101s/2717s\n",
      "TRAIN    loss : 0.01980    f1 : 0.98492\n",
      "Val    loss : 0.21475    f1 : 0.78463\n",
      "epoch : 44/70    time : 101s/2623s\n",
      "TRAIN    loss : 0.02484    f1 : 0.97957\n",
      "Val    loss : 0.28115    f1 : 0.80277\n",
      "epoch : 45/70    time : 101s/2524s\n",
      "TRAIN    loss : 0.03112    f1 : 0.97546\n",
      "Val    loss : 0.26652    f1 : 0.80531\n",
      "epoch : 46/70    time : 101s/2418s\n",
      "TRAIN    loss : 0.02957    f1 : 0.96612\n",
      "Val    loss : 0.21069    f1 : 0.81835\n",
      "epoch : 47/70    time : 101s/2315s\n",
      "TRAIN    loss : 0.03005    f1 : 0.96635\n",
      "Val    loss : 0.23252    f1 : 0.79277\n",
      "-----------------SAVE:48 epoch----------------\n",
      "epoch : 48/70    time : 101s/2219s\n",
      "TRAIN    loss : 0.03215    f1 : 0.97203\n",
      "Val    loss : 0.19460    f1 : 0.86126\n",
      "epoch : 49/70    time : 101s/2114s\n",
      "TRAIN    loss : 0.03952    f1 : 0.97599\n",
      "Val    loss : 0.24662    f1 : 0.76521\n",
      "epoch : 50/70    time : 101s/2014s\n",
      "TRAIN    loss : 0.00989    f1 : 0.99017\n",
      "Val    loss : 0.21902    f1 : 0.80547\n",
      "epoch : 51/70    time : 101s/1916s\n",
      "TRAIN    loss : 0.02426    f1 : 0.97174\n",
      "Val    loss : 0.28213    f1 : 0.76531\n",
      "epoch : 52/70    time : 101s/1815s\n",
      "TRAIN    loss : 0.02209    f1 : 0.98304\n",
      "Val    loss : 0.26731    f1 : 0.82545\n",
      "epoch : 53/70    time : 101s/1716s\n",
      "TRAIN    loss : 0.01492    f1 : 0.98707\n",
      "Val    loss : 0.26769    f1 : 0.85359\n",
      "epoch : 54/70    time : 101s/1612s\n",
      "TRAIN    loss : 0.02141    f1 : 0.98697\n",
      "Val    loss : 0.22487    f1 : 0.83449\n",
      "epoch : 55/70    time : 101s/1512s\n",
      "TRAIN    loss : 0.01536    f1 : 0.98270\n",
      "Val    loss : 0.23654    f1 : 0.81776\n",
      "epoch : 56/70    time : 101s/1411s\n",
      "TRAIN    loss : 0.03981    f1 : 0.96735\n",
      "Val    loss : 0.23023    f1 : 0.81791\n",
      "epoch : 57/70    time : 101s/1308s\n",
      "TRAIN    loss : 0.02213    f1 : 0.98927\n",
      "Val    loss : 0.18884    f1 : 0.84750\n",
      "epoch : 58/70    time : 101s/1206s\n",
      "TRAIN    loss : 0.02256    f1 : 0.98275\n",
      "Val    loss : 0.19966    f1 : 0.83689\n",
      "epoch : 59/70    time : 101s/1106s\n",
      "TRAIN    loss : 0.00930    f1 : 0.99596\n",
      "Val    loss : 0.22836    f1 : 0.81653\n",
      "epoch : 60/70    time : 101s/1007s\n",
      "TRAIN    loss : 0.03409    f1 : 0.96054\n",
      "Val    loss : 0.29832    f1 : 0.80473\n",
      "epoch : 61/70    time : 101s/906s\n",
      "TRAIN    loss : 0.02483    f1 : 0.97650\n",
      "Val    loss : 0.19176    f1 : 0.81591\n",
      "epoch : 62/70    time : 101s/805s\n",
      "TRAIN    loss : 0.02253    f1 : 0.97815\n",
      "Val    loss : 0.23006    f1 : 0.83572\n",
      "epoch : 63/70    time : 101s/705s\n",
      "TRAIN    loss : 0.01317    f1 : 0.98789\n",
      "Val    loss : 0.28498    f1 : 0.76653\n",
      "epoch : 64/70    time : 101s/605s\n",
      "TRAIN    loss : 0.02782    f1 : 0.97516\n",
      "Val    loss : 0.30419    f1 : 0.80233\n",
      "epoch : 65/70    time : 101s/504s\n",
      "TRAIN    loss : 0.01915    f1 : 0.98212\n",
      "Val    loss : 0.23082    f1 : 0.81780\n",
      "epoch : 66/70    time : 101s/404s\n",
      "TRAIN    loss : 0.01903    f1 : 0.97309\n",
      "Val    loss : 0.27393    f1 : 0.79990\n",
      "epoch : 67/70    time : 101s/304s\n",
      "TRAIN    loss : 0.01803    f1 : 0.98396\n",
      "Val    loss : 0.21554    f1 : 0.82035\n",
      "epoch : 68/70    time : 101s/202s\n",
      "TRAIN    loss : 0.01778    f1 : 0.98533\n",
      "Val    loss : 0.21947    f1 : 0.84162\n",
      "----------fold_2 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 112s/7745s\n",
      "TRAIN    loss : 1.06458    f1 : 0.19895\n",
      "Val    loss : 0.65561    f1 : 0.30943\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 101s/6898s\n",
      "TRAIN    loss : 0.55256    f1 : 0.37621\n",
      "Val    loss : 0.45683    f1 : 0.41953\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 101s/6787s\n",
      "TRAIN    loss : 0.37549    f1 : 0.54113\n",
      "Val    loss : 0.29004    f1 : 0.59395\n",
      "epoch : 4/70    time : 101s/6678s\n",
      "TRAIN    loss : 0.27158    f1 : 0.65908\n",
      "Val    loss : 0.33098    f1 : 0.54590\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 102s/6599s\n",
      "TRAIN    loss : 0.20809    f1 : 0.72371\n",
      "Val    loss : 0.24904    f1 : 0.64645\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 102s/6501s\n",
      "TRAIN    loss : 0.15717    f1 : 0.81029\n",
      "Val    loss : 0.21239    f1 : 0.71483\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 101s/6391s\n",
      "TRAIN    loss : 0.14692    f1 : 0.81365\n",
      "Val    loss : 0.24183    f1 : 0.72047\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 101s/6280s\n",
      "TRAIN    loss : 0.12841    f1 : 0.83437\n",
      "Val    loss : 0.24245    f1 : 0.73634\n",
      "epoch : 9/70    time : 101s/6174s\n",
      "TRAIN    loss : 0.09404    f1 : 0.88259\n",
      "Val    loss : 0.19013    f1 : 0.71569\n",
      "epoch : 10/70    time : 101s/6081s\n",
      "TRAIN    loss : 0.10736    f1 : 0.87576\n",
      "Val    loss : 0.22303    f1 : 0.71971\n",
      "epoch : 11/70    time : 101s/5979s\n",
      "TRAIN    loss : 0.07016    f1 : 0.92716\n",
      "Val    loss : 0.25130    f1 : 0.69202\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 12/70    time : 102s/5890s\n",
      "TRAIN    loss : 0.07532    f1 : 0.92440\n",
      "Val    loss : 0.23869    f1 : 0.76385\n",
      "epoch : 13/70    time : 101s/5781s\n",
      "TRAIN    loss : 0.07356    f1 : 0.94098\n",
      "Val    loss : 0.21904    f1 : 0.75958\n",
      "epoch : 14/70    time : 101s/5676s\n",
      "TRAIN    loss : 0.08726    f1 : 0.91698\n",
      "Val    loss : 0.25140    f1 : 0.70373\n",
      "epoch : 15/70    time : 101s/5578s\n",
      "TRAIN    loss : 0.07436    f1 : 0.93654\n",
      "Val    loss : 0.25544    f1 : 0.66768\n",
      "epoch : 16/70    time : 101s/5475s\n",
      "TRAIN    loss : 0.05182    f1 : 0.93792\n",
      "Val    loss : 0.23631    f1 : 0.70438\n",
      "epoch : 17/70    time : 105s/5547s\n",
      "TRAIN    loss : 0.04360    f1 : 0.95741\n",
      "Val    loss : 0.19573    f1 : 0.73667\n",
      "-----------------SAVE:18 epoch----------------\n",
      "epoch : 18/70    time : 108s/5598s\n",
      "TRAIN    loss : 0.05206    f1 : 0.93883\n",
      "Val    loss : 0.17341    f1 : 0.78428\n",
      "-----------------SAVE:19 epoch----------------\n",
      "epoch : 19/70    time : 108s/5488s\n",
      "TRAIN    loss : 0.04861    f1 : 0.96097\n",
      "Val    loss : 0.23472    f1 : 0.79617\n",
      "-----------------SAVE:20 epoch----------------\n",
      "epoch : 20/70    time : 108s/5392s\n",
      "TRAIN    loss : 0.04431    f1 : 0.96254\n",
      "Val    loss : 0.24293    f1 : 0.80686\n",
      "epoch : 21/70    time : 107s/5256s\n",
      "TRAIN    loss : 0.04736    f1 : 0.94999\n",
      "Val    loss : 0.24345    f1 : 0.79795\n",
      "epoch : 22/70    time : 103s/4930s\n",
      "TRAIN    loss : 0.04793    f1 : 0.95413\n",
      "Val    loss : 0.29408    f1 : 0.73598\n",
      "epoch : 23/70    time : 102s/4810s\n",
      "TRAIN    loss : 0.06048    f1 : 0.94142\n",
      "Val    loss : 0.20291    f1 : 0.77091\n",
      "epoch : 24/70    time : 102s/4704s\n",
      "TRAIN    loss : 0.03638    f1 : 0.95844\n",
      "Val    loss : 0.30412    f1 : 0.75935\n",
      "epoch : 25/70    time : 103s/4649s\n",
      "TRAIN    loss : 0.04607    f1 : 0.96046\n",
      "Val    loss : 0.24078    f1 : 0.77806\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/70    time : 105s/4608s\n",
      "TRAIN    loss : 0.04125    f1 : 0.96819\n",
      "Val    loss : 0.25932    f1 : 0.81294\n",
      "-----------------SAVE:27 epoch----------------\n",
      "epoch : 27/70    time : 104s/4493s\n",
      "TRAIN    loss : 0.01891    f1 : 0.97576\n",
      "Val    loss : 0.21846    f1 : 0.83719\n",
      "epoch : 28/70    time : 104s/4381s\n",
      "TRAIN    loss : 0.01433    f1 : 0.98289\n",
      "Val    loss : 0.28547    f1 : 0.80942\n",
      "epoch : 29/70    time : 105s/4290s\n",
      "TRAIN    loss : 0.04866    f1 : 0.95937\n",
      "Val    loss : 0.32607    f1 : 0.73534\n",
      "epoch : 30/70    time : 103s/4132s\n",
      "TRAIN    loss : 0.03586    f1 : 0.95868\n",
      "Val    loss : 0.19322    f1 : 0.80359\n",
      "epoch : 31/70    time : 103s/4020s\n",
      "TRAIN    loss : 0.02719    f1 : 0.97178\n",
      "Val    loss : 0.24938    f1 : 0.79366\n",
      "epoch : 32/70    time : 105s/4000s\n",
      "TRAIN    loss : 0.02651    f1 : 0.97601\n",
      "Val    loss : 0.29947    f1 : 0.75213\n",
      "epoch : 33/70    time : 103s/3797s\n",
      "TRAIN    loss : 0.03139    f1 : 0.96270\n",
      "Val    loss : 0.31691    f1 : 0.75753\n",
      "epoch : 34/70    time : 106s/3814s\n",
      "TRAIN    loss : 0.01466    f1 : 0.98472\n",
      "Val    loss : 0.23055    f1 : 0.76430\n",
      "epoch : 35/70    time : 103s/3592s\n",
      "TRAIN    loss : 0.04680    f1 : 0.96362\n",
      "Val    loss : 0.22837    f1 : 0.76996\n",
      "epoch : 36/70    time : 103s/3509s\n",
      "TRAIN    loss : 0.03328    f1 : 0.96374\n",
      "Val    loss : 0.23160    f1 : 0.78666\n",
      "epoch : 37/70    time : 102s/3379s\n",
      "TRAIN    loss : 0.05295    f1 : 0.95392\n",
      "Val    loss : 0.27927    f1 : 0.72273\n",
      "epoch : 38/70    time : 102s/3279s\n",
      "TRAIN    loss : 0.03104    f1 : 0.97014\n",
      "Val    loss : 0.28984    f1 : 0.79075\n",
      "epoch : 39/70    time : 105s/3256s\n",
      "TRAIN    loss : 0.02966    f1 : 0.97290\n",
      "Val    loss : 0.28347    f1 : 0.73623\n",
      "epoch : 40/70    time : 107s/3210s\n",
      "TRAIN    loss : 0.02592    f1 : 0.97436\n",
      "Val    loss : 0.20929    f1 : 0.76220\n",
      "epoch : 41/70    time : 106s/3083s\n",
      "TRAIN    loss : 0.01393    f1 : 0.98568\n",
      "Val    loss : 0.27593    f1 : 0.75776\n",
      "epoch : 42/70    time : 104s/2901s\n",
      "TRAIN    loss : 0.02812    f1 : 0.98185\n",
      "Val    loss : 0.21024    f1 : 0.78486\n",
      "epoch : 43/70    time : 103s/2783s\n",
      "TRAIN    loss : 0.01306    f1 : 0.98707\n",
      "Val    loss : 0.21536    f1 : 0.82131\n",
      "epoch : 44/70    time : 103s/2686s\n",
      "TRAIN    loss : 0.03727    f1 : 0.97778\n",
      "Val    loss : 0.21114    f1 : 0.76882\n",
      "epoch : 45/70    time : 106s/2661s\n",
      "TRAIN    loss : 0.02465    f1 : 0.97500\n",
      "Val    loss : 0.22209    f1 : 0.81491\n",
      "epoch : 46/70    time : 103s/2475s\n",
      "TRAIN    loss : 0.01926    f1 : 0.98332\n",
      "Val    loss : 0.23120    f1 : 0.79576\n",
      "epoch : 47/70    time : 102s/2357s\n",
      "TRAIN    loss : 0.02158    f1 : 0.97993\n",
      "Val    loss : 0.45630    f1 : 0.80344\n",
      "----------fold_3 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 104s/7207s\n",
      "TRAIN    loss : 1.07633    f1 : 0.17665\n",
      "Val    loss : 0.69019    f1 : 0.34730\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 104s/7052s\n",
      "TRAIN    loss : 0.54510    f1 : 0.39115\n",
      "Val    loss : 0.42679    f1 : 0.48498\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 105s/7015s\n",
      "TRAIN    loss : 0.37990    f1 : 0.52818\n",
      "Val    loss : 0.32346    f1 : 0.55154\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 104s/6889s\n",
      "TRAIN    loss : 0.28518    f1 : 0.65776\n",
      "Val    loss : 0.32943    f1 : 0.56321\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 105s/6856s\n",
      "TRAIN    loss : 0.21957    f1 : 0.72731\n",
      "Val    loss : 0.23129    f1 : 0.67450\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 6/70    time : 103s/6572s\n",
      "TRAIN    loss : 0.16460    f1 : 0.79526\n",
      "Val    loss : 0.27191    f1 : 0.67519\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 104s/6542s\n",
      "TRAIN    loss : 0.15030    f1 : 0.82867\n",
      "Val    loss : 0.23547    f1 : 0.72570\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 8/70    time : 104s/6432s\n",
      "TRAIN    loss : 0.13279    f1 : 0.86015\n",
      "Val    loss : 0.16454    f1 : 0.81459\n",
      "epoch : 9/70    time : 104s/6321s\n",
      "TRAIN    loss : 0.10791    f1 : 0.87727\n",
      "Val    loss : 0.18071    f1 : 0.75433\n",
      "epoch : 10/70    time : 103s/6163s\n",
      "TRAIN    loss : 0.10151    f1 : 0.87831\n",
      "Val    loss : 0.22240    f1 : 0.78843\n",
      "epoch : 11/70    time : 103s/6067s\n",
      "TRAIN    loss : 0.09702    f1 : 0.90090\n",
      "Val    loss : 0.23292    f1 : 0.78750\n",
      "epoch : 12/70    time : 103s/5947s\n",
      "TRAIN    loss : 0.07715    f1 : 0.91064\n",
      "Val    loss : 0.25504    f1 : 0.73321\n",
      "epoch : 13/70    time : 103s/5863s\n",
      "TRAIN    loss : 0.06063    f1 : 0.92190\n",
      "Val    loss : 0.24966    f1 : 0.76975\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 14/70    time : 106s/5953s\n",
      "TRAIN    loss : 0.08329    f1 : 0.91905\n",
      "Val    loss : 0.15154    f1 : 0.81924\n",
      "epoch : 15/70    time : 104s/5711s\n",
      "TRAIN    loss : 0.09346    f1 : 0.91189\n",
      "Val    loss : 0.18222    f1 : 0.80796\n",
      "epoch : 16/70    time : 104s/5613s\n",
      "TRAIN    loss : 0.06727    f1 : 0.92520\n",
      "Val    loss : 0.20840    f1 : 0.76500\n",
      "-----------------SAVE:17 epoch----------------\n",
      "epoch : 17/70    time : 104s/5514s\n",
      "TRAIN    loss : 0.05447    f1 : 0.92998\n",
      "Val    loss : 0.16190    f1 : 0.85906\n",
      "epoch : 18/70    time : 104s/5390s\n",
      "TRAIN    loss : 0.04484    f1 : 0.95500\n",
      "Val    loss : 0.17959    f1 : 0.77934\n",
      "epoch : 19/70    time : 104s/5296s\n",
      "TRAIN    loss : 0.04729    f1 : 0.95286\n",
      "Val    loss : 0.22870    f1 : 0.75422\n",
      "epoch : 20/70    time : 104s/5195s\n",
      "TRAIN    loss : 0.05065    f1 : 0.95970\n",
      "Val    loss : 0.27395    f1 : 0.82728\n",
      "epoch : 21/70    time : 104s/5079s\n",
      "TRAIN    loss : 0.07635    f1 : 0.92997\n",
      "Val    loss : 0.17383    f1 : 0.80066\n",
      "epoch : 22/70    time : 104s/4996s\n",
      "TRAIN    loss : 0.04902    f1 : 0.95931\n",
      "Val    loss : 0.19106    f1 : 0.81810\n",
      "epoch : 23/70    time : 104s/4878s\n",
      "TRAIN    loss : 0.03128    f1 : 0.96784\n",
      "Val    loss : 0.30090    f1 : 0.81879\n",
      "epoch : 24/70    time : 104s/4774s\n",
      "TRAIN    loss : 0.05850    f1 : 0.95060\n",
      "Val    loss : 0.16926    f1 : 0.79132\n",
      "epoch : 25/70    time : 104s/4667s\n",
      "TRAIN    loss : 0.04126    f1 : 0.95385\n",
      "Val    loss : 0.16320    f1 : 0.81186\n",
      "-----------------SAVE:26 epoch----------------\n",
      "epoch : 26/70    time : 104s/4583s\n",
      "TRAIN    loss : 0.04639    f1 : 0.95662\n",
      "Val    loss : 0.17250    f1 : 0.86441\n",
      "epoch : 27/70    time : 104s/4472s\n",
      "TRAIN    loss : 0.03219    f1 : 0.95698\n",
      "Val    loss : 0.22366    f1 : 0.82762\n",
      "epoch : 28/70    time : 104s/4376s\n",
      "TRAIN    loss : 0.02794    f1 : 0.96595\n",
      "Val    loss : 0.21515    f1 : 0.79940\n",
      "epoch : 29/70    time : 104s/4270s\n",
      "TRAIN    loss : 0.06539    f1 : 0.93817\n",
      "Val    loss : 0.25123    f1 : 0.79656\n",
      "epoch : 30/70    time : 104s/4167s\n",
      "TRAIN    loss : 0.03235    f1 : 0.97157\n",
      "Val    loss : 0.19206    f1 : 0.80668\n",
      "epoch : 31/70    time : 104s/4064s\n",
      "TRAIN    loss : 0.03160    f1 : 0.96460\n",
      "Val    loss : 0.22349    f1 : 0.80347\n",
      "epoch : 32/70    time : 104s/3955s\n",
      "TRAIN    loss : 0.04120    f1 : 0.94685\n",
      "Val    loss : 0.18400    f1 : 0.82092\n",
      "epoch : 33/70    time : 104s/3862s\n",
      "TRAIN    loss : 0.03967    f1 : 0.96571\n",
      "Val    loss : 0.18230    f1 : 0.81713\n",
      "epoch : 34/70    time : 104s/3750s\n",
      "TRAIN    loss : 0.03192    f1 : 0.96623\n",
      "Val    loss : 0.28843    f1 : 0.81689\n",
      "epoch : 35/70    time : 104s/3645s\n",
      "TRAIN    loss : 0.03908    f1 : 0.96551\n",
      "Val    loss : 0.24385    f1 : 0.78580\n",
      "epoch : 36/70    time : 104s/3543s\n",
      "TRAIN    loss : 0.03669    f1 : 0.96257\n",
      "Val    loss : 0.15545    f1 : 0.82249\n",
      "epoch : 37/70    time : 104s/3432s\n",
      "TRAIN    loss : 0.02133    f1 : 0.98171\n",
      "Val    loss : 0.13868    f1 : 0.83806\n",
      "epoch : 38/70    time : 104s/3334s\n",
      "TRAIN    loss : 0.01681    f1 : 0.98888\n",
      "Val    loss : 0.13202    f1 : 0.85599\n",
      "epoch : 39/70    time : 104s/3228s\n",
      "TRAIN    loss : 0.02533    f1 : 0.97358\n",
      "Val    loss : 0.18166    f1 : 0.83224\n",
      "epoch : 40/70    time : 104s/3123s\n",
      "TRAIN    loss : 0.03524    f1 : 0.97232\n",
      "Val    loss : 0.18098    f1 : 0.79305\n",
      "epoch : 41/70    time : 104s/3021s\n",
      "TRAIN    loss : 0.03317    f1 : 0.97198\n",
      "Val    loss : 0.49825    f1 : 0.82007\n",
      "epoch : 42/70    time : 104s/2912s\n",
      "TRAIN    loss : 0.04856    f1 : 0.95576\n",
      "Val    loss : 0.52147    f1 : 0.80800\n",
      "epoch : 43/70    time : 104s/2806s\n",
      "TRAIN    loss : 0.03166    f1 : 0.95587\n",
      "Val    loss : 0.22384    f1 : 0.77925\n",
      "epoch : 44/70    time : 104s/2706s\n",
      "TRAIN    loss : 0.01852    f1 : 0.97802\n",
      "Val    loss : 0.20219    f1 : 0.82688\n",
      "epoch : 45/70    time : 104s/2602s\n",
      "TRAIN    loss : 0.01809    f1 : 0.98051\n",
      "Val    loss : 0.24015    f1 : 0.81190\n",
      "epoch : 46/70    time : 104s/2501s\n",
      "TRAIN    loss : 0.01537    f1 : 0.97676\n",
      "Val    loss : 0.30176    f1 : 0.79853\n",
      "----------fold_4 start!----------\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 1/70    time : 104s/7207s\n",
      "TRAIN    loss : 1.06547    f1 : 0.20822\n",
      "Val    loss : 0.67766    f1 : 0.33686\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 2/70    time : 105s/7124s\n",
      "TRAIN    loss : 0.54948    f1 : 0.37148\n",
      "Val    loss : 0.42680    f1 : 0.51273\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 3/70    time : 104s/6991s\n",
      "TRAIN    loss : 0.35713    f1 : 0.54923\n",
      "Val    loss : 0.29271    f1 : 0.57548\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 4/70    time : 105s/6899s\n",
      "TRAIN    loss : 0.28501    f1 : 0.64398\n",
      "Val    loss : 0.22721    f1 : 0.68297\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 5/70    time : 104s/6773s\n",
      "TRAIN    loss : 0.22143    f1 : 0.74236\n",
      "Val    loss : 0.23221    f1 : 0.69497\n",
      "epoch : 6/70    time : 104s/6656s\n",
      "TRAIN    loss : 0.16752    f1 : 0.79907\n",
      "Val    loss : 0.22043    f1 : 0.69138\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 7/70    time : 104s/6551s\n",
      "TRAIN    loss : 0.13633    f1 : 0.82560\n",
      "Val    loss : 0.23535    f1 : 0.70951\n",
      "epoch : 8/70    time : 104s/6452s\n",
      "TRAIN    loss : 0.14346    f1 : 0.82839\n",
      "Val    loss : 0.29614    f1 : 0.68432\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 9/70    time : 104s/6372s\n",
      "TRAIN    loss : 0.10716    f1 : 0.87869\n",
      "Val    loss : 0.23450    f1 : 0.77598\n",
      "epoch : 10/70    time : 104s/6245s\n",
      "TRAIN    loss : 0.08202    f1 : 0.89358\n",
      "Val    loss : 0.26081    f1 : 0.76607\n",
      "epoch : 11/70    time : 104s/6125s\n",
      "TRAIN    loss : 0.08304    f1 : 0.90747\n",
      "Val    loss : 0.28451    f1 : 0.71935\n",
      "epoch : 12/70    time : 104s/6028s\n",
      "TRAIN    loss : 0.06806    f1 : 0.92531\n",
      "Val    loss : 0.25538    f1 : 0.73834\n",
      "epoch : 13/70    time : 104s/5919s\n",
      "TRAIN    loss : 0.08098    f1 : 0.91029\n",
      "Val    loss : 0.45043    f1 : 0.74182\n",
      "epoch : 14/70    time : 104s/5811s\n",
      "TRAIN    loss : 0.07353    f1 : 0.92474\n",
      "Val    loss : 0.22634    f1 : 0.76094\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 15/70    time : 104s/5722s\n",
      "TRAIN    loss : 0.06316    f1 : 0.92237\n",
      "Val    loss : 0.20772    f1 : 0.80354\n",
      "-----------------SAVE:16 epoch----------------\n",
      "epoch : 16/70    time : 104s/5614s\n",
      "TRAIN    loss : 0.06727    f1 : 0.94412\n",
      "Val    loss : 0.16451    f1 : 0.82306\n",
      "epoch : 17/70    time : 104s/5497s\n",
      "TRAIN    loss : 0.04940    f1 : 0.95039\n",
      "Val    loss : 0.22942    f1 : 0.79299\n",
      "epoch : 18/70    time : 104s/5403s\n",
      "TRAIN    loss : 0.03838    f1 : 0.96169\n",
      "Val    loss : 0.23019    f1 : 0.81428\n",
      "epoch : 19/70    time : 104s/5295s\n",
      "TRAIN    loss : 0.05027    f1 : 0.94003\n",
      "Val    loss : 0.23839    f1 : 0.76167\n",
      "epoch : 20/70    time : 104s/5188s\n",
      "TRAIN    loss : 0.06352    f1 : 0.94425\n",
      "Val    loss : 0.24489    f1 : 0.75400\n",
      "epoch : 21/70    time : 104s/5097s\n",
      "TRAIN    loss : 0.04530    f1 : 0.95383\n",
      "Val    loss : 0.21551    f1 : 0.82029\n",
      "epoch : 22/70    time : 104s/4984s\n",
      "TRAIN    loss : 0.02716    f1 : 0.97747\n",
      "Val    loss : 0.22031    f1 : 0.78073\n",
      "epoch : 23/70    time : 104s/4869s\n",
      "TRAIN    loss : 0.03744    f1 : 0.95984\n",
      "Val    loss : 0.26837    f1 : 0.80702\n",
      "epoch : 24/70    time : 104s/4767s\n",
      "TRAIN    loss : 0.05101    f1 : 0.95161\n",
      "Val    loss : 0.31036    f1 : 0.80892\n",
      "epoch : 25/70    time : 104s/4675s\n",
      "TRAIN    loss : 0.05350    f1 : 0.94036\n",
      "Val    loss : 0.31196    f1 : 0.75957\n",
      "epoch : 26/70    time : 104s/4561s\n",
      "TRAIN    loss : 0.04849    f1 : 0.94717\n",
      "Val    loss : 0.25987    f1 : 0.79657\n",
      "epoch : 27/70    time : 104s/4464s\n",
      "TRAIN    loss : 0.04074    f1 : 0.95000\n",
      "Val    loss : 0.30193    f1 : 0.81000\n",
      "epoch : 28/70    time : 104s/4362s\n",
      "TRAIN    loss : 0.05189    f1 : 0.95668\n",
      "Val    loss : 0.21539    f1 : 0.77344\n",
      "epoch : 29/70    time : 104s/4255s\n",
      "TRAIN    loss : 0.06042    f1 : 0.93958\n",
      "Val    loss : 0.26259    f1 : 0.81723\n",
      "epoch : 30/70    time : 104s/4154s\n",
      "TRAIN    loss : 0.03683    f1 : 0.95990\n",
      "Val    loss : 0.25973    f1 : 0.79124\n",
      "epoch : 31/70    time : 104s/4046s\n",
      "TRAIN    loss : 0.01516    f1 : 0.98500\n",
      "Val    loss : 0.22205    f1 : 0.82133\n",
      "epoch : 32/70    time : 104s/3946s\n",
      "TRAIN    loss : 0.01026    f1 : 0.99288\n",
      "Val    loss : 0.16956    f1 : 0.81048\n",
      "-----------------SAVE:33 epoch----------------\n",
      "epoch : 33/70    time : 104s/3848s\n",
      "TRAIN    loss : 0.03701    f1 : 0.96311\n",
      "Val    loss : 0.25271    f1 : 0.82418\n",
      "epoch : 34/70    time : 104s/3729s\n",
      "TRAIN    loss : 0.04765    f1 : 0.95604\n",
      "Val    loss : 0.33194    f1 : 0.76750\n",
      "epoch : 35/70    time : 104s/3636s\n",
      "TRAIN    loss : 0.02834    f1 : 0.97297\n",
      "Val    loss : 0.33296    f1 : 0.79296\n",
      "epoch : 36/70    time : 104s/3532s\n",
      "TRAIN    loss : 0.05426    f1 : 0.94902\n",
      "Val    loss : 0.24983    f1 : 0.80125\n",
      "epoch : 37/70    time : 104s/3431s\n",
      "TRAIN    loss : 0.02727    f1 : 0.97213\n",
      "Val    loss : 0.18113    f1 : 0.78661\n",
      "epoch : 38/70    time : 103s/3312s\n",
      "TRAIN    loss : 0.02854    f1 : 0.97797\n",
      "Val    loss : 0.39496    f1 : 0.78943\n",
      "epoch : 39/70    time : 103s/3208s\n",
      "TRAIN    loss : 0.02792    f1 : 0.98058\n",
      "Val    loss : 0.46418    f1 : 0.76953\n",
      "epoch : 40/70    time : 103s/3101s\n",
      "TRAIN    loss : 0.01923    f1 : 0.98247\n",
      "Val    loss : 0.29953    f1 : 0.76280\n",
      "epoch : 41/70    time : 104s/3002s\n",
      "TRAIN    loss : 0.01978    f1 : 0.97857\n",
      "Val    loss : 0.33324    f1 : 0.74999\n",
      "epoch : 42/70    time : 104s/2904s\n",
      "TRAIN    loss : 0.02716    f1 : 0.98139\n",
      "Val    loss : 0.50377    f1 : 0.73562\n",
      "epoch : 43/70    time : 104s/2805s\n",
      "TRAIN    loss : 0.03561    f1 : 0.95733\n",
      "Val    loss : 0.78650    f1 : 0.76133\n",
      "epoch : 44/70    time : 104s/2706s\n",
      "TRAIN    loss : 0.03807    f1 : 0.97001\n",
      "Val    loss : 0.28248    f1 : 0.78279\n",
      "-----------------SAVE:45 epoch----------------\n",
      "epoch : 45/70    time : 105s/2619s\n",
      "TRAIN    loss : 0.03700    f1 : 0.96404\n",
      "Val    loss : 0.25430    f1 : 0.86200\n",
      "epoch : 46/70    time : 104s/2490s\n",
      "TRAIN    loss : 0.01876    f1 : 0.98469\n",
      "Val    loss : 0.27260    f1 : 0.85192\n",
      "epoch : 47/70    time : 104s/2389s\n",
      "TRAIN    loss : 0.02769    f1 : 0.98484\n",
      "Val    loss : 0.23724    f1 : 0.80850\n",
      "epoch : 48/70    time : 104s/2289s\n",
      "TRAIN    loss : 0.02783    f1 : 0.97559\n",
      "Val    loss : 0.27793    f1 : 0.82228\n",
      "epoch : 49/70    time : 104s/2180s\n",
      "TRAIN    loss : 0.02240    f1 : 0.98438\n",
      "Val    loss : 0.23207    f1 : 0.83520\n",
      "epoch : 50/70    time : 105s/2092s\n",
      "TRAIN    loss : 0.02867    f1 : 0.97737\n",
      "Val    loss : 0.25485    f1 : 0.80462\n",
      "epoch : 51/70    time : 102s/1946s\n",
      "TRAIN    loss : 0.01992    f1 : 0.98437\n",
      "Val    loss : 0.23439    f1 : 0.81466\n",
      "epoch : 52/70    time : 103s/1848s\n",
      "TRAIN    loss : 0.02072    f1 : 0.98176\n",
      "Val    loss : 0.26522    f1 : 0.80774\n",
      "epoch : 53/70    time : 103s/1745s\n",
      "TRAIN    loss : 0.02458    f1 : 0.96920\n",
      "Val    loss : 0.38382    f1 : 0.82536\n",
      "epoch : 54/70    time : 102s/1638s\n",
      "TRAIN    loss : 0.01634    f1 : 0.98211\n",
      "Val    loss : 0.31027    f1 : 0.80937\n",
      "epoch : 55/70    time : 102s/1533s\n",
      "TRAIN    loss : 0.01991    f1 : 0.98061\n",
      "Val    loss : 0.28074    f1 : 0.77319\n",
      "epoch : 56/70    time : 102s/1434s\n",
      "TRAIN    loss : 0.02415    f1 : 0.97041\n",
      "Val    loss : 0.30339    f1 : 0.79641\n",
      "epoch : 57/70    time : 104s/1347s\n",
      "TRAIN    loss : 0.03186    f1 : 0.96877\n",
      "Val    loss : 0.34303    f1 : 0.79027\n",
      "epoch : 58/70    time : 104s/1243s\n",
      "TRAIN    loss : 0.02408    f1 : 0.97253\n",
      "Val    loss : 0.34681    f1 : 0.78423\n",
      "epoch : 59/70    time : 104s/1144s\n",
      "TRAIN    loss : 0.02235    f1 : 0.98452\n",
      "Val    loss : 0.26394    f1 : 0.79660\n",
      "epoch : 60/70    time : 104s/1039s\n",
      "TRAIN    loss : 0.00839    f1 : 0.98806\n",
      "Val    loss : 0.25248    f1 : 0.80158\n",
      "epoch : 61/70    time : 104s/936s\n",
      "TRAIN    loss : 0.01962    f1 : 0.97566\n",
      "Val    loss : 0.38401    f1 : 0.79689\n",
      "epoch : 62/70    time : 104s/831s\n",
      "TRAIN    loss : 0.03638    f1 : 0.96657\n",
      "Val    loss : 0.31605    f1 : 0.79819\n",
      "epoch : 63/70    time : 104s/728s\n",
      "TRAIN    loss : 0.03505    f1 : 0.97344\n",
      "Val    loss : 0.25015    f1 : 0.78920\n",
      "epoch : 64/70    time : 104s/624s\n",
      "TRAIN    loss : 0.04010    f1 : 0.96597\n",
      "Val    loss : 0.36401    f1 : 0.75067\n",
      "epoch : 65/70    time : 104s/521s\n",
      "TRAIN    loss : 0.01848    f1 : 0.98319\n",
      "Val    loss : 0.32618    f1 : 0.83593\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022,shuffle=True)\n",
    "batch_size = 8\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "    print(\"----------fold_{} start!----------\".format(idx))\n",
    "    t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "    t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "    # Train\n",
    "    train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    # Val\n",
    "    val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "    val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    best=0\n",
    "\n",
    "    model = Network().to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "    best_f1 = 0\n",
    "    early_stopping = 0\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        train_loss = 0\n",
    "        train_pred=[]\n",
    "        train_y=[]\n",
    "        model.train()\n",
    "        for batch in (train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()/len(train_loader)\n",
    "            train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += y.detach().cpu().numpy().tolist()\n",
    "        train_f1 = score_function(train_y, train_pred)\n",
    "        state_dict= model.state_dict()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0 \n",
    "            val_pred = []\n",
    "            val_y = []\n",
    "        \n",
    "\n",
    "        for batch in (val_loader):\n",
    "            x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "            y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_val = model(x_val)\n",
    "            loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "            val_loss += loss_val.item()/len(val_loader)\n",
    "            val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "            val_y += y_val.detach().cpu().numpy().tolist()\n",
    "        val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "        if val_f1 > best_f1:\n",
    "            best_epoch = epoch\n",
    "            best_loss = val_loss\n",
    "            best_f1 = val_f1\n",
    "            early_stopping = 0\n",
    "\n",
    "            torch.save({'epoch':epoch,\n",
    "                        'state_dict':state_dict,\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'scaler': scaler.state_dict(),\n",
    "                }, './save/best_model_{}.pth'.format(idx))\n",
    "            print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "        else:\n",
    "            early_stopping += 1\n",
    "\n",
    "                # Early Stopping\n",
    "        if early_stopping == 20:\n",
    "            TIME = time.time() - start\n",
    "            print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "            print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "            print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "            break\n",
    "\n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 32\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(5):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load(('./save/best_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1])+ np.array(pred_ensemble[3]) + np.array(pred_ensemble[4]) )/4\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"./open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./open/b3_norm_epoch70.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "best=0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./open/b3_norm.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
