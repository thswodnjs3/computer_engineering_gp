{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbde0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf0c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/work/nlos/dacon/'\n",
    "train_y = pd.read_csv(path +\"open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]\n",
    "\n",
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (512, 512),interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "train_png = sorted(glob(path + 'open/train/*.png'))\n",
    "test_png = sorted(glob(path + 'open/test/*.png'))\n",
    "\n",
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
    "\n",
    "np.save(path + 'train_imgs_512', np.array(train_imgs))\n",
    "np.save(path + 'test_imgs_512', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb14b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load(path + 'train_imgs_512.npy')\n",
    "test_imgs = np.load(path + 'test_imgs_512.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a84437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "          train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.433038, 0.403458, 0.394151],\n",
    "                                     std = [0.181572, 0.174035, 0.163234]),\n",
    "                transforms.RandomAffine((-45, 45)),\n",
    "                \n",
    "            ])\n",
    "          img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "          test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.418256, 0.393101, 0.386632],\n",
    "                                     std = [0.195055, 0.190053, 0.185323])\n",
    "            ])\n",
    "          img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('tf_efficientnet_b7', pretrained=True, num_classes=88, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('tf_efficientnet_b7', pretrained=True, num_classes=88, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becf93b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_224_in22k',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_224_in22k',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'botnet26t_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_s16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'jx_nest_base',\n",
       " 'jx_nest_small',\n",
       " 'jx_nest_tiny',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_384',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_resnet50',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_224_dino',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_224_dino',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'sebotnet33ts_256',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'seresnet33ts',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_efficientnetv2_xl_in21ft1k',\n",
       " 'tf_efficientnetv2_xl_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_sam_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_sam_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception65',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_224_dist',\n",
       " 'xcit_large_24_p8_384_dist',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_224_dist',\n",
       " 'xcit_large_24_p16_384_dist',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_224_dist',\n",
       " 'xcit_medium_24_p8_384_dist',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_224_dist',\n",
       " 'xcit_medium_24_p16_384_dist',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_224_dist',\n",
       " 'xcit_nano_12_p8_384_dist',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_224_dist',\n",
       " 'xcit_nano_12_p16_384_dist',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_224_dist',\n",
       " 'xcit_small_12_p8_384_dist',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_224_dist',\n",
       " 'xcit_small_12_p16_384_dist',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_224_dist',\n",
       " 'xcit_small_24_p8_384_dist',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_224_dist',\n",
       " 'xcit_small_24_p16_384_dist',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_224_dist',\n",
       " 'xcit_tiny_12_p8_384_dist',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_224_dist',\n",
       " 'xcit_tiny_12_p16_384_dist',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_224_dist',\n",
       " 'xcit_tiny_24_p8_384_dist',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_224_dist',\n",
       " 'xcit_tiny_24_p16_384_dist']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "301f662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f07894be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5b4e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------fold_0 start!----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b7_ra-6c08e654.pth\" to /home/work/.cache/torch/hub/checkpoints/tf_efficientnet_b7_ra-6c08e654.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/70    time : 250s/17231s\n",
      "TRAIN loss : 0.94196    f1 : 0.27240\n",
      "Val loss : 0.47311    f1 : 0.40396\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 2/70    time : 199s/13544s\n",
      "TRAIN loss : 0.42969    f1 : 0.51438\n",
      "Val loss : 0.33368    f1 : 0.58627\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 3/70    time : 193s/12935s\n",
      "TRAIN loss : 0.27892    f1 : 0.64860\n",
      "Val loss : 0.29562    f1 : 0.67576\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 4/70    time : 197s/13001s\n",
      "TRAIN loss : 0.20088    f1 : 0.77730\n",
      "Val loss : 0.34773    f1 : 0.70293\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 5/70    time : 192s/12505s\n",
      "TRAIN loss : 0.16500    f1 : 0.78881\n",
      "Val loss : 0.22464    f1 : 0.72374\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 6/70    time : 191s/12226s\n",
      "TRAIN loss : 0.13344    f1 : 0.85716\n",
      "Val loss : 0.20481    f1 : 0.73020\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 7/70    time : 187s/11766s\n",
      "TRAIN loss : 0.09576    f1 : 0.89142\n",
      "Val loss : 0.28261    f1 : 0.71680\n",
      "epoch : 8/70    time : 182s/11313s\n",
      "TRAIN loss : 0.09230    f1 : 0.91580\n",
      "Val loss : 0.16256    f1 : 0.79531\n",
      "-----------------SAVE:8 epoch----------------\n",
      "epoch : 9/70    time : 166s/10134s\n",
      "TRAIN loss : 0.11057    f1 : 0.89909\n",
      "Val loss : 0.14790    f1 : 0.76959\n",
      "epoch : 10/70    time : 147s/8838s\n",
      "TRAIN loss : 0.06128    f1 : 0.95357\n",
      "Val loss : 0.30935    f1 : 0.75782\n",
      "epoch : 11/70    time : 146s/8595s\n",
      "TRAIN loss : 0.08857    f1 : 0.90111\n",
      "Val loss : 0.20615    f1 : 0.77623\n",
      "epoch : 12/70    time : 140s/8124s\n",
      "TRAIN loss : 0.06112    f1 : 0.94054\n",
      "Val loss : 0.14002    f1 : 0.82521\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 13/70    time : 140s/7957s\n",
      "TRAIN loss : 0.05658    f1 : 0.94220\n",
      "Val loss : 0.31516    f1 : 0.75655\n",
      "epoch : 14/70    time : 153s/8566s\n",
      "TRAIN loss : 0.08129    f1 : 0.92102\n",
      "Val loss : 0.13485    f1 : 0.85450\n",
      "-----------------SAVE:14 epoch----------------\n",
      "epoch : 15/70    time : 142s/7811s\n",
      "TRAIN loss : 0.05586    f1 : 0.94805\n",
      "Val loss : 0.14651    f1 : 0.78585\n",
      "epoch : 16/70    time : 122s/6570s\n",
      "TRAIN loss : 0.04731    f1 : 0.95224\n",
      "Val loss : 0.31006    f1 : 0.73039\n",
      "epoch : 17/70    time : 121s/6425s\n",
      "TRAIN loss : 0.05548    f1 : 0.95129\n",
      "Val loss : 0.21445    f1 : 0.77841\n",
      "epoch : 18/70    time : 111s/5761s\n",
      "TRAIN loss : 0.04740    f1 : 0.95286\n",
      "Val loss : 0.15497    f1 : 0.79445\n",
      "epoch : 19/70    time : 114s/5805s\n",
      "TRAIN loss : 0.03564    f1 : 0.95876\n",
      "Val loss : 0.23156    f1 : 0.79122\n",
      "epoch : 20/70    time : 121s/6027s\n",
      "TRAIN loss : 0.06734    f1 : 0.93944\n",
      "Val loss : 0.17516    f1 : 0.76272\n",
      "epoch : 21/70    time : 120s/5876s\n",
      "TRAIN loss : 0.03423    f1 : 0.96062\n",
      "Val loss : 0.16405    f1 : 0.79453\n",
      "epoch : 22/70    time : 115s/5502s\n",
      "TRAIN loss : 0.03403    f1 : 0.96475\n",
      "Val loss : 0.13446    f1 : 0.83998\n",
      "epoch : 23/70    time : 117s/5490s\n",
      "TRAIN loss : 0.06830    f1 : 0.93412\n",
      "Val loss : 0.21259    f1 : 0.70512\n",
      "epoch : 24/70    time : 121s/5577s\n",
      "TRAIN loss : 0.05378    f1 : 0.94755\n",
      "Val loss : 0.19712    f1 : 0.80223\n",
      "epoch : 25/70    time : 119s/5350s\n",
      "TRAIN loss : 0.06611    f1 : 0.95098\n",
      "Val loss : 0.31953    f1 : 0.69467\n",
      "epoch : 26/70    time : 126s/5548s\n",
      "TRAIN loss : 0.03968    f1 : 0.95344\n",
      "Val loss : 0.17633    f1 : 0.75545\n",
      "epoch : 27/70    time : 131s/5641s\n",
      "TRAIN loss : 0.03887    f1 : 0.96564\n",
      "Val loss : 0.17674    f1 : 0.79645\n",
      "epoch : 28/70    time : 133s/5576s\n",
      "TRAIN loss : 0.04690    f1 : 0.95786\n",
      "Val loss : 0.20662    f1 : 0.81629\n",
      "epoch : 29/70    time : 129s/5286s\n",
      "TRAIN loss : 0.01789    f1 : 0.97990\n",
      "Val loss : 0.19786    f1 : 0.76403\n",
      "epoch : 30/70    time : 129s/5154s\n",
      "TRAIN loss : 0.01723    f1 : 0.98103\n",
      "Val loss : 0.13807    f1 : 0.80591\n",
      "epoch : 31/70    time : 123s/4800s\n",
      "TRAIN loss : 0.01999    f1 : 0.97273\n",
      "Val loss : 0.24380    f1 : 0.72524\n",
      "epoch : 32/70    time : 126s/4796s\n",
      "TRAIN loss : 0.06146    f1 : 0.94859\n",
      "Val loss : 0.22526    f1 : 0.75672\n",
      "epoch : 33/70    time : 140s/5170s\n",
      "TRAIN loss : 0.03975    f1 : 0.97384\n",
      "Val loss : 0.15389    f1 : 0.80711\n",
      "epoch : 34/70    time : 133s/4801s\n",
      "TRAIN loss : 0.01894    f1 : 0.98467\n",
      "Val loss : 0.21802    f1 : 0.79290\n",
      "----------fold_1 start!----------\n",
      "epoch : 1/70    time : 147s/10162s\n",
      "TRAIN loss : 0.91790    f1 : 0.25187\n",
      "Val loss : 0.48150    f1 : 0.40286\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 2/70    time : 134s/9113s\n",
      "TRAIN loss : 0.40282    f1 : 0.50449\n",
      "Val loss : 0.30030    f1 : 0.56764\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 3/70    time : 135s/9027s\n",
      "TRAIN loss : 0.28204    f1 : 0.65869\n",
      "Val loss : 0.25185    f1 : 0.66053\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 4/70    time : 135s/8935s\n",
      "TRAIN loss : 0.20410    f1 : 0.78579\n",
      "Val loss : 0.22900    f1 : 0.70676\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 5/70    time : 127s/8265s\n",
      "TRAIN loss : 0.17177    f1 : 0.80631\n",
      "Val loss : 0.21220    f1 : 0.72487\n",
      "-----------------SAVE:5 epoch----------------\n",
      "epoch : 6/70    time : 132s/8417s\n",
      "TRAIN loss : 0.15077    f1 : 0.83114\n",
      "Val loss : 0.21392    f1 : 0.72726\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 7/70    time : 130s/8178s\n",
      "TRAIN loss : 0.07819    f1 : 0.89969\n",
      "Val loss : 0.18911    f1 : 0.78775\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 8/70    time : 131s/8149s\n",
      "TRAIN loss : 0.10161    f1 : 0.89334\n",
      "Val loss : 0.23445    f1 : 0.76674\n",
      "epoch : 10/70    time : 137s/8203s\n",
      "TRAIN loss : 0.07647    f1 : 0.91044\n",
      "Val loss : 0.15808    f1 : 0.79369\n",
      "-----------------SAVE:10 epoch----------------\n",
      "epoch : 11/70    time : 137s/8075s\n",
      "TRAIN loss : 0.06208    f1 : 0.94235\n",
      "Val loss : 0.22236    f1 : 0.76015\n",
      "epoch : 12/70    time : 139s/8081s\n",
      "TRAIN loss : 0.08805    f1 : 0.89852\n",
      "Val loss : 0.14416    f1 : 0.82850\n",
      "-----------------SAVE:12 epoch----------------\n",
      "epoch : 13/70    time : 136s/7732s\n",
      "TRAIN loss : 0.04125    f1 : 0.94975\n",
      "Val loss : 0.32272    f1 : 0.76668\n",
      "epoch : 14/70    time : 134s/7507s\n",
      "TRAIN loss : 0.05810    f1 : 0.94308\n",
      "Val loss : 0.17647    f1 : 0.77682\n",
      "epoch : 15/70    time : 137s/7513s\n",
      "TRAIN loss : 0.08095    f1 : 0.91676\n",
      "Val loss : 0.27807    f1 : 0.75429\n",
      "epoch : 16/70    time : 147s/7914s\n",
      "TRAIN loss : 0.06231    f1 : 0.94038\n",
      "Val loss : 0.26893    f1 : 0.74918\n",
      "epoch : 17/70    time : 142s/7531s\n",
      "TRAIN loss : 0.07565    f1 : 0.92022\n",
      "Val loss : 0.18401    f1 : 0.82124\n",
      "epoch : 18/70    time : 132s/6847s\n",
      "TRAIN loss : 0.05526    f1 : 0.95052\n",
      "Val loss : 0.17374    f1 : 0.82175\n",
      "epoch : 19/70    time : 140s/7148s\n",
      "TRAIN loss : 0.03399    f1 : 0.97015\n",
      "Val loss : 0.19329    f1 : 0.78816\n",
      "epoch : 20/70    time : 139s/6974s\n",
      "TRAIN loss : 0.04213    f1 : 0.95749\n",
      "Val loss : 0.23559    f1 : 0.79818\n",
      "epoch : 22/70    time : 136s/6540s\n",
      "TRAIN loss : 0.04095    f1 : 0.95719\n",
      "Val loss : 0.18908    f1 : 0.81226\n",
      "epoch : 23/70    time : 140s/6579s\n",
      "TRAIN loss : 0.04200    f1 : 0.95901\n",
      "Val loss : 0.21813    f1 : 0.79156\n",
      "epoch : 24/70    time : 143s/6593s\n",
      "TRAIN loss : 0.06075    f1 : 0.94214\n",
      "Val loss : 0.20223    f1 : 0.78129\n",
      "epoch : 25/70    time : 145s/6534s\n",
      "TRAIN loss : 0.03779    f1 : 0.95928\n",
      "Val loss : 0.19284    f1 : 0.80280\n",
      "epoch : 26/70    time : 140s/6146s\n",
      "TRAIN loss : 0.04040    f1 : 0.96553\n",
      "Val loss : 0.20390    f1 : 0.80703\n",
      "epoch : 27/70    time : 152s/6519s\n",
      "TRAIN loss : 0.02553    f1 : 0.97941\n",
      "Val loss : 0.22323    f1 : 0.78063\n",
      "epoch : 28/70    time : 140s/5893s\n",
      "TRAIN loss : 0.05366    f1 : 0.95100\n",
      "Val loss : 0.17914    f1 : 0.80606\n",
      "epoch : 29/70    time : 131s/5370s\n",
      "TRAIN loss : 0.03107    f1 : 0.96887\n",
      "Val loss : 0.15481    f1 : 0.84975\n",
      "-----------------SAVE:29 epoch----------------\n",
      "epoch : 30/70    time : 128s/5111s\n",
      "TRAIN loss : 0.03316    f1 : 0.98087\n",
      "Val loss : 0.18365    f1 : 0.81538\n",
      "epoch : 31/70    time : 132s/5132s\n",
      "TRAIN loss : 0.01355    f1 : 0.98656\n",
      "Val loss : 0.14890    f1 : 0.84705\n",
      "epoch : 32/70    time : 123s/4679s\n",
      "TRAIN loss : 0.01867    f1 : 0.97922\n",
      "Val loss : 0.22715    f1 : 0.86175\n",
      "-----------------SAVE:32 epoch----------------\n",
      "epoch : 33/70    time : 117s/4329s\n",
      "TRAIN loss : 0.04404    f1 : 0.95256\n",
      "Val loss : 0.17046    f1 : 0.83692\n",
      "epoch : 34/70    time : 120s/4338s\n",
      "TRAIN loss : 0.03937    f1 : 0.97068\n",
      "Val loss : 0.22489    f1 : 0.77567\n",
      "epoch : 35/70    time : 117s/4084s\n",
      "TRAIN loss : 0.01838    f1 : 0.97491\n",
      "Val loss : 0.18140    f1 : 0.78425\n",
      "epoch : 36/70    time : 122s/4144s\n",
      "TRAIN loss : 0.01618    f1 : 0.98849\n",
      "Val loss : 0.18808    f1 : 0.81043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 37/70    time : 120s/3951s\n",
      "TRAIN loss : 0.02550    f1 : 0.97920\n",
      "Val loss : 0.16500    f1 : 0.80182\n",
      "epoch : 38/70    time : 120s/3837s\n",
      "TRAIN loss : 0.01845    f1 : 0.97732\n",
      "Val loss : 0.24546    f1 : 0.79961\n",
      "epoch : 39/70    time : 110s/3408s\n",
      "TRAIN loss : 0.10364    f1 : 0.89643\n",
      "Val loss : 0.24929    f1 : 0.78571\n",
      "epoch : 40/70    time : 116s/3469s\n",
      "TRAIN loss : 0.03983    f1 : 0.96313\n",
      "Val loss : 0.16540    f1 : 0.79856\n",
      "epoch : 41/70    time : 121s/3511s\n",
      "TRAIN loss : 0.03034    f1 : 0.97426\n",
      "Val loss : 0.19747    f1 : 0.80152\n",
      "epoch : 42/70    time : 130s/3653s\n",
      "TRAIN loss : 0.04422    f1 : 0.97016\n",
      "Val loss : 0.18134    f1 : 0.77563\n",
      "epoch : 43/70    time : 119s/3222s\n",
      "TRAIN loss : 0.03113    f1 : 0.96361\n",
      "Val loss : 0.19009    f1 : 0.81404\n",
      "epoch : 44/70    time : 133s/3445s\n",
      "TRAIN loss : 0.04356    f1 : 0.95587\n",
      "Val loss : 0.16235    f1 : 0.83003\n",
      "epoch : 45/70    time : 127s/3173s\n",
      "TRAIN loss : 0.03494    f1 : 0.97479\n",
      "Val loss : 0.25174    f1 : 0.82103\n",
      "epoch : 46/70    time : 132s/3174s\n",
      "TRAIN loss : 0.02445    f1 : 0.97355\n",
      "Val loss : 0.16125    f1 : 0.81352\n",
      "epoch : 47/70    time : 119s/2742s\n",
      "TRAIN loss : 0.01382    f1 : 0.98402\n",
      "Val loss : 0.22267    f1 : 0.80133\n",
      "epoch : 48/70    time : 121s/2654s\n",
      "TRAIN loss : 0.01674    f1 : 0.98276\n",
      "Val loss : 0.19183    f1 : 0.81604\n",
      "epoch : 49/70    time : 127s/2662s\n",
      "TRAIN loss : 0.01148    f1 : 0.98897\n",
      "Val loss : 0.19311    f1 : 0.82069\n",
      "epoch : 50/70    time : 122s/2442s\n",
      "TRAIN loss : 0.02039    f1 : 0.97902\n",
      "Val loss : 0.21600    f1 : 0.75750\n",
      "epoch : 51/70    time : 122s/2310s\n",
      "TRAIN loss : 0.02741    f1 : 0.97754\n",
      "Val loss : 0.20124    f1 : 0.81075\n",
      "epoch : 52/70    time : 126s/2266s\n",
      "TRAIN loss : 0.02901    f1 : 0.97612\n",
      "Val loss : 0.18094    f1 : 0.82736\n",
      "----------fold_2 start!----------\n",
      "epoch : 1/70    time : 141s/9698s\n",
      "TRAIN loss : 0.95753    f1 : 0.27349\n",
      "Val loss : 0.47838    f1 : 0.38972\n",
      "-----------------SAVE:1 epoch----------------\n",
      "epoch : 2/70    time : 127s/8607s\n",
      "TRAIN loss : 0.40703    f1 : 0.52574\n",
      "Val loss : 0.35442    f1 : 0.54388\n",
      "-----------------SAVE:2 epoch----------------\n",
      "epoch : 3/70    time : 127s/8522s\n",
      "TRAIN loss : 0.26467    f1 : 0.68872\n",
      "Val loss : 0.21535    f1 : 0.71508\n",
      "-----------------SAVE:3 epoch----------------\n",
      "epoch : 4/70    time : 127s/8390s\n",
      "TRAIN loss : 0.18444    f1 : 0.77856\n",
      "Val loss : 0.26279    f1 : 0.72399\n",
      "-----------------SAVE:4 epoch----------------\n",
      "epoch : 5/70    time : 123s/7983s\n",
      "TRAIN loss : 0.15309    f1 : 0.81853\n",
      "Val loss : 0.25713    f1 : 0.71928\n",
      "epoch : 6/70    time : 121s/7745s\n",
      "TRAIN loss : 0.12617    f1 : 0.86608\n",
      "Val loss : 0.18107    f1 : 0.78414\n",
      "-----------------SAVE:6 epoch----------------\n",
      "epoch : 7/70    time : 120s/7579s\n",
      "TRAIN loss : 0.09803    f1 : 0.89038\n",
      "Val loss : 0.17800    f1 : 0.80038\n",
      "-----------------SAVE:7 epoch----------------\n",
      "epoch : 8/70    time : 121s/7515s\n",
      "TRAIN loss : 0.07488    f1 : 0.89968\n",
      "Val loss : 0.23330    f1 : 0.75813\n",
      "epoch : 9/70    time : 127s/7763s\n",
      "TRAIN loss : 0.04913    f1 : 0.95507\n",
      "Val loss : 0.21073    f1 : 0.80547\n",
      "-----------------SAVE:9 epoch----------------\n",
      "epoch : 10/70    time : 123s/7400s\n",
      "TRAIN loss : 0.06306    f1 : 0.93645\n",
      "Val loss : 0.30439    f1 : 0.76430\n",
      "epoch : 11/70    time : 126s/7415s\n",
      "TRAIN loss : 0.06855    f1 : 0.93275\n",
      "Val loss : 0.20245    f1 : 0.82346\n",
      "-----------------SAVE:11 epoch----------------\n",
      "epoch : 13/70    time : 126s/7158s\n",
      "TRAIN loss : 0.04290    f1 : 0.94976\n",
      "Val loss : 0.20854    f1 : 0.80673\n",
      "epoch : 14/70    time : 127s/7106s\n",
      "TRAIN loss : 0.06109    f1 : 0.93799\n",
      "Val loss : 0.21921    f1 : 0.77851\n",
      "epoch : 15/70    time : 125s/6899s\n",
      "TRAIN loss : 0.04515    f1 : 0.96383\n",
      "Val loss : 0.20745    f1 : 0.84227\n",
      "-----------------SAVE:15 epoch----------------\n",
      "epoch : 16/70    time : 132s/7137s\n",
      "TRAIN loss : 0.07128    f1 : 0.94206\n",
      "Val loss : 0.22299    f1 : 0.79543\n",
      "epoch : 17/70    time : 136s/7206s\n",
      "TRAIN loss : 0.07932    f1 : 0.91610\n",
      "Val loss : 0.29155    f1 : 0.72805\n",
      "epoch : 18/70    time : 152s/7896s\n",
      "TRAIN loss : 0.06943    f1 : 0.93328\n",
      "Val loss : 0.25362    f1 : 0.79235\n",
      "epoch : 19/70    time : 157s/8009s\n",
      "TRAIN loss : 0.03896    f1 : 0.95653\n",
      "Val loss : 0.26004    f1 : 0.83109\n",
      "epoch : 20/70    time : 169s/8473s\n",
      "TRAIN loss : 0.04670    f1 : 0.95385\n",
      "Val loss : 0.26647    f1 : 0.81820\n",
      "epoch : 21/70    time : 162s/7951s\n",
      "TRAIN loss : 0.03255    f1 : 0.98135\n",
      "Val loss : 0.21718    f1 : 0.83149\n",
      "epoch : 22/70    time : 173s/8298s\n",
      "TRAIN loss : 0.07036    f1 : 0.94490\n",
      "Val loss : 0.19066    f1 : 0.81208\n",
      "epoch : 24/70    time : 153s/7029s\n",
      "TRAIN loss : 0.05255    f1 : 0.94344\n",
      "Val loss : 0.19537    f1 : 0.79108\n",
      "epoch : 25/70    time : 172s/7718s\n",
      "TRAIN loss : 0.03316    f1 : 0.95468\n",
      "Val loss : 0.17473    f1 : 0.85884\n",
      "-----------------SAVE:25 epoch----------------\n",
      "epoch : 26/70    time : 160s/7021s\n",
      "TRAIN loss : 0.02653    f1 : 0.96417\n",
      "Val loss : 0.19698    f1 : 0.82986\n",
      "epoch : 27/70    time : 157s/6751s\n",
      "TRAIN loss : 0.02701    f1 : 0.96720\n",
      "Val loss : 0.40436    f1 : 0.76554\n",
      "epoch : 28/70    time : 165s/6948s\n",
      "TRAIN loss : 0.04387    f1 : 0.95407\n",
      "Val loss : 0.29932    f1 : 0.77867\n",
      "epoch : 29/70    time : 161s/6601s\n",
      "TRAIN loss : 0.02407    f1 : 0.97497\n",
      "Val loss : 0.35057    f1 : 0.78817\n",
      "epoch : 30/70    time : 161s/6446s\n",
      "TRAIN loss : 0.07385    f1 : 0.93688\n",
      "Val loss : 0.23221    f1 : 0.81813\n",
      "epoch : 31/70    time : 169s/6588s\n",
      "TRAIN loss : 0.03339    f1 : 0.96266\n",
      "Val loss : 0.20232    f1 : 0.80198\n",
      "epoch : 32/70    time : 158s/5988s\n",
      "TRAIN loss : 0.02456    f1 : 0.96577\n",
      "Val loss : 0.18528    f1 : 0.82664\n",
      "epoch : 33/70    time : 157s/5794s\n",
      "TRAIN loss : 0.02354    f1 : 0.97636\n",
      "Val loss : 0.20972    f1 : 0.83720\n",
      "epoch : 34/70    time : 173s/6219s\n",
      "TRAIN loss : 0.01075    f1 : 0.99107\n",
      "Val loss : 0.18188    f1 : 0.87526\n",
      "-----------------SAVE:34 epoch----------------\n",
      "epoch : 35/70    time : 151s/5280s\n",
      "TRAIN loss : 0.03879    f1 : 0.96923\n",
      "Val loss : 0.26598    f1 : 0.80467\n",
      "epoch : 36/70    time : 162s/5501s\n",
      "TRAIN loss : 0.03811    f1 : 0.95794\n",
      "Val loss : 0.20508    f1 : 0.82713\n",
      "epoch : 37/70    time : 154s/5076s\n",
      "TRAIN loss : 0.03651    f1 : 0.96749\n",
      "Val loss : 0.18554    f1 : 0.85047\n",
      "epoch : 38/70    time : 147s/4699s\n",
      "TRAIN loss : 0.01811    f1 : 0.98107\n",
      "Val loss : 0.15260    f1 : 0.87066\n",
      "epoch : 39/70    time : 167s/5172s\n",
      "TRAIN loss : 0.01183    f1 : 0.98916\n",
      "Val loss : 0.41378    f1 : 0.81601\n",
      "epoch : 40/70    time : 150s/4510s\n",
      "TRAIN loss : 0.02597    f1 : 0.98176\n",
      "Val loss : 0.21655    f1 : 0.80325\n",
      "epoch : 41/70    time : 160s/4627s\n",
      "TRAIN loss : 0.07438    f1 : 0.93546\n",
      "Val loss : 0.29460    f1 : 0.75021\n",
      "epoch : 42/70    time : 161s/4513s\n",
      "TRAIN loss : 0.03200    f1 : 0.97016\n",
      "Val loss : 0.26630    f1 : 0.80459\n",
      "epoch : 43/70    time : 155s/4172s\n",
      "TRAIN loss : 0.03669    f1 : 0.96090\n",
      "Val loss : 0.24668    f1 : 0.83473\n",
      "epoch : 44/70    time : 153s/3975s\n",
      "TRAIN loss : 0.03758    f1 : 0.95871\n",
      "Val loss : 0.25554    f1 : 0.83696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d13f7355defd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d9ae7776083d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/timm/models/efficientnet_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Point-wise linear projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_pwl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle=True)\n",
    "batch_size = 16\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(train_imgs, np.array(train_labels))):\n",
    "    print(\"----------fold_{} start!----------\".format(idx))\n",
    "    t_imgs, val_imgs = train_imgs[train_idx],  train_imgs[val_idx]\n",
    "    t_labels, val_labels = np.array(train_labels)[train_idx], np.array(train_labels)[val_idx]\n",
    "\n",
    "    # Train\n",
    "    train_dataset = Custom_dataset(np.array(t_imgs), np.array(t_labels), mode='train')\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    # Val\n",
    "    val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), mode='test')\n",
    "    val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    best=0\n",
    "\n",
    "    model = Network().to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "    best_f1 = 0\n",
    "    early_stopping = 0\n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        train_loss = 0\n",
    "        train_pred=[]\n",
    "        train_y=[]\n",
    "        model.train()\n",
    "        for batch in (train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()/len(train_loader)\n",
    "            train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            train_y += y.detach().cpu().numpy().tolist()\n",
    "        train_f1 = score_function(train_y, train_pred)\n",
    "        state_dict= model.state_dict()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0 \n",
    "            val_pred = []\n",
    "            val_y = []\n",
    "\n",
    "\n",
    "        for batch in (val_loader):\n",
    "            x_val = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "            y_val = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_val = model(x_val)\n",
    "            loss_val = criterion(pred_val, y_val)\n",
    "\n",
    "            val_loss += loss_val.item()/len(val_loader)\n",
    "            val_pred += pred_val.argmax(1).detach().cpu().numpy().tolist()\n",
    "            val_y += y_val.detach().cpu().numpy().tolist()\n",
    "        val_f1 = score_function(val_y, val_pred)\n",
    "\n",
    "        \n",
    "        TIME = time.time() - start\n",
    "        print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "        print(f'TRAIN loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
    "        print(f'Val loss : {val_loss:.5f}    f1 : {val_f1:.5f}')\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_epoch = epoch\n",
    "            best_loss = val_loss\n",
    "            best_f1 = val_f1\n",
    "            early_stopping = 0\n",
    "\n",
    "            torch.save({'epoch':epoch,\n",
    "                        'state_dict':state_dict,\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'scaler': scaler.state_dict(),\n",
    "                 }, path +'b7_512_model_{}.pth'.format(idx))\n",
    "            print('-----------------SAVE:{} epoch----------------'.format(best_epoch+1))\n",
    "        else:\n",
    "            early_stopping += 1\n",
    "            # Early Stopping\n",
    "        if early_stopping == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecdff022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 32\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "for i in range(3):\n",
    "  model_test = Network(mode = 'test').to(device)\n",
    "  model_test.load_state_dict(torch.load((path+'b7_512_model_{}.pth'.format(i)))['state_dict'])\n",
    "  model_test.eval()\n",
    "  pred_prob = []\n",
    "  with torch.no_grad():\n",
    "      for batch in (test_loader):\n",
    "          x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "          with torch.cuda.amp.autocast():\n",
    "              pred = model_test(x)\n",
    "              pred_prob.extend(pred.detach().cpu().numpy())\n",
    "      pred_ensemble.append(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc172b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (np.array(pred_ensemble[0])+ np.array(pred_ensemble[1]) + np.array(pred_ensemble[2]))/3\n",
    "f_pred = np.array(pred).argmax(1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a959aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97334aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + \"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7978ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path + \"b7_512_ensemble.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691109a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10 (NGC 21.11/Python 3.8 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
