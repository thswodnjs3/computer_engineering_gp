{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.a_function import make_labels\n",
    "from src.a_variable import train_y\n",
    "\n",
    "imgs = np.load('./save/1-stage-myimg-train-384.npy')\n",
    "labels, label_unique = make_labels(train_y, target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_img, val_img, train_label, val_label = train_test_split(\n",
    "#     imgs, labels, test_size=0.2, stratify=labels\n",
    "# )\n",
    "# train_ratio = Counter(train_label)\n",
    "# over_label = [key for key in train_ratio.keys() if train_ratio[key]>100]\n",
    "# over_set = [(img, label) for img, label in zip(train_img, train_label) if label in over_label]\n",
    "# over_img = [x[0] for x in over_set]\n",
    "# over_label = [x[1] for x in over_set]\n",
    "# print(len(train_img), len(over_img), len(over_label))\n",
    "\n",
    "# val_ratio = Counter(val_label)\n",
    "# over_label = [val_ratio[key] for key in val_ratio.keys()]\n",
    "# sorted(over_label, reverse=True)\n",
    "# # over_set = [(img, label) for img, label in zip(train_img, train_label) if label in over_label]\n",
    "# # over_img = [x[0] for x in over_set]\n",
    "# # over_label = [x[1] for x in over_set]\n",
    "# # print(len(train_img), len(over_img), len(over_label))\n",
    "# # [(label, train_ratio[label]) for img, label in zip(train_img, train_label) if label in over_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_label), len(val_label))\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "# train_ratio = Counter(train_label)\n",
    "# val_ratio = Counter(val_label)\n",
    "\n",
    "# print('Labels:', len(train_ratio.keys()), len(val_ratio.keys()))\n",
    "# for train_key, val_key in zip(sorted(train_ratio.keys()), sorted(val_ratio.keys())):\n",
    "#     print(f'Train - {train_key}: {train_ratio[train_key]}, Val - {val_key}: {val_ratio[val_key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\손재원\\AppData\\Local\\Temp/ipykernel_17488/3984189453.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.a_variable import device\n",
    "from src.a_class import Network\n",
    "from src.a_compilation import make_data, make_test_loader, make_submission\n",
    "\n",
    "stage = '1-stage'\n",
    "size = 384\n",
    "\n",
    "lr = 2e-4\n",
    "wd = 2e-2\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "aug_on = True\n",
    "aug_state = 'On' if aug_on else 'Off'\n",
    "\n",
    "under_multiple=2\n",
    "\n",
    "train_imgs, train_labels, label_unique, test_imgs = make_data(stage, size)\n",
    "test_loader = make_test_loader(test_imgs, batch_size)\n",
    "\n",
    "model_test = Network(len(label_unique), mode='test').to(device)\n",
    "model_test.load_state_dict(torch.load(('./save/best_model_2.pth'))['state_dict'])\n",
    "model_test.eval()\n",
    "pred_prob = []\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model_test(x)\n",
    "        pred = pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        pred_prob.extend(pred)\n",
    "\n",
    "make_submission(label_unique, pred_prob,\n",
    "                stage, size, aug_state, under_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([98.2954305 , 99.63859728, 95.27581109]),\n",
       " array([92.71169027, 92.71169027, 92.71169027])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "xxx = np.load('./save/1-stage-myimg-test-384.npy')\n",
    "[np.mean(x, axis=(0,1)) for x in xxx[:2]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
